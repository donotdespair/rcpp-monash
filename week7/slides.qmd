---
title: ETC4500/ETC5450 Advanced&nbsp;R&nbsp;programming
author: "Week 7: Reactive programming with targets and renv"
format:
  presentation-beamer:
    fontsize: "14pt,t"
    section-titles: false
    knitr:
      opts_chunk:
        dev: "cairo_pdf"
    fig-width: 7.5
    fig-height: 3.5
    include-in-header: ../header.tex
    colorlinks: true
    urlcolor: MonashBlue
    linkcolor: burntorange
---

```{r}
#| label: setup
#| include: false
#| cache: false
source(here::here("setup.R"))
source(here::here("course_info.R"))
```

# Reactive programming

## Regular (imperative) programming

Consider how code is usually evaluated...

```{r, eval = FALSE}
a <- 1
b <- 2
x <- a + b
x
```

What is `x`?

```{r, eval = FALSE}
a <- -1
x
```

What is `x` now?

## Regular (imperative) programming

::: {.callout-tip title="Predictable programming"}
All programming we've seen so far evaluates code in sequential order, line by line.

\hspace{1em}

Since `x` was not re-evaluated, its value stays the same even when its inputs have changed.
:::

<!-- . . . -->

<!-- *Note: this is why it's especially important to ensure code works when ran from top to bottom, since when doing a data analysis we often write and run code more freely!* -->

## Reactive programming

Within a reactive programming paradigm, objects *react* to changes in their inputs and automatically update their value!

. . .

::: {.callout-warning title="Disclaimer"}
Reactive programming is a broad and diverse paradigm, we'll focus only on the basic concepts and how they apply in shiny applications.
:::

## Reactive programming

We can implement *reactivity* with functions & environments.

```{r}
library(rlang)
react <- function(e) new_function(alist(), expr(eval(!!enexpr(e))))
```

We'll learn how this function works later (metaprogramming).

Reactive programming is also smarter about *'invalidation'*, results are **cached and reused** if the inputs aren't changed.

## Reactive programming

How does reactive programming differ?

```{r, eval = FALSE}
a <- 1
b <- 2
y <- react(a + b)
y()
```

What is `y`?

```{r, eval = FALSE}
a <- -1
y()
```

What is `y` now?

## Reactive programming

::: {.callout-tip title="(Un)predictable programming?"}
Reactive programming can be disorienting!

\hspace{1em}

Reactive objects *invalidate* whenever their inputs change, and so its value will be recalculated and stay up-to-date.
:::

## Reactive programming

::: {.callout-caution title="Your turn!"}
<!-- Experiment with using `react()` in R. -->

<!-- ```{r} -->
<!-- library(rlang) -->
<!-- react <- function(e) new_function(alist(), expr(eval(!!enexpr(e)))) -->
<!-- ``` -->

```{r, eval = FALSE}
a <- 1
b <- 2
y <- react(a + b)
y()
```

When was `a + b` evaluated?

\vspace{1em}

How does this differ from ordinary (imperative) code?
:::

## Imperative and declarative programming

\fontsize{13}{13}\sf
::: {.callout-note icon=false title="Imperative programming"}
* Specific commands are carried out immediately.
* Usually direct and exact instructions.
* e.g. read in data from this file.
:::

::: {.callout-note icon=false title="Declarative programming"}
* Specific commands are carried out when needed.
* Expresses higher order goals / constraints.
* e.g. make sure this dataset is up to date every time I see it.
:::

## Use cases for reactive programming

\fontsize{13}{13}\sf
::: {.callout-important title="Use-less cases"}
This paradigm is rarely needed or used in R for data analysis.
:::

::: {.callout-tip title="Useful cases"}
Reactive programming is useful for developing user applications (including web apps!).

\vspace{1em}

In R, the shiny package uses reactive programming for writing app interactivity.
:::

# Caching

## Caching: using rds

```{r}
#| eval: false
if (file.exists("results.rds")) {
  res <- readRDS("results.rds")
} else {
  res <- compute_it()  # a time-consuming function
  saveRDS(res, "results.rds")
}
```

\pause\vspace*{1cm}

\alert{Equivalently\dots}

```{r}
#| eval: false
res <- xfun::cache_rds(
  compute_it(), # a time-consuming function
  file = "results.rds"
)
```

## Caching: using rds
\fontsize{10}{10}\sf

```{r}
#| label: cache1
#| cache: false
#| freeze: false
compute <- function(...) {
    xfun::cache_rds(rnorm(6), file = "results.rds", ...)
}
compute()
compute()
```

```{r}
#| include: false
#| cache: false
# Need to explicitly remove results.rds for some reason when doing this in quarto
file.remove(here::here("cache/results.rds"))
```

```{r}
#| label: cache2
#| cache: false
#| freeze: false
compute(rerun = TRUE)
compute()
```

## Caching: Rmarkdown

````{verbatim}
```{r import-data, cache=TRUE}
d <- read.csv('my-precious.csv')
```

```{r analysis, dependson='import-data', cache=TRUE}
summary(d)
```
````

* Requires explicit dependencies or changes not detected.
* Changes to functions or packages not detected.
* Good practice to frequently clear cache to avoid problems.
* targets is a better solution: Week 8

## Caching: Quarto

````{verbatim}
```{r}
#| label: import-data
#| cache: true
d <- read.csv('my-precious.csv')
```

```{r}
#| label: analysis
#| dependson: import-data
#| cache: true
summary(d)
```
````

* Same problems as Rmarkdown
* targets is a better solution: Week 8

## Caching: memoise

Caching stores results of computations so they can be reused.

\fontsize{10}{10}\sf

```{r}
library(memoise)
sq <- function(x) {
  print("Computing square of 'x'")
  x**2
}
memo_sq <- memoise(sq)
memo_sq(2)
memo_sq(2)
```

# targets

## targets: reproducible computation at scale

\placefig{0.5}{1.8}{width=5cm}{images/logo.png}

\begin{textblock}{15}(0.5,8.5)
\textcolor{gray}{\footnotesize Some images from https://wlandau.github.io/targets-tutorial}
\end{textblock}

\begin{textblock}{10}(6, 2)
\begin{itemize}
\item Supports a clean, modular, function-oriented programming style.
\item Learns how your pipeline fits together.
\item Runs only the necessary computation.
\item Abstracts files as R objects.
\item Similar to Makefiles, but with R functions.
\end{itemize}
\end{textblock}

## Interconnected tasks

\only<1>{\placefig{0.5}{2}{width=13cm}{images/workflow.png}}
\only<2>{\placefig{0.5}{2}{width=13cm}{images/change.png}}
\only<3>{\placefig{0.5}{2}{width=13cm}{images/downstream.png}}

## Dilemma: short runtimes or reproducible results?

\fullheight{images/decisions.png}

## Let a pipeline tool do the work

\fullwidth{images/pipeline_graph.png}\vspace*{-0.15cm}

* Save time while ensuring computational reproducibility.
* Automatically skip tasks that are already up to date.

## Typical project structure

```{verbatim}
_targets.R # Required top-level configuration file.
R/
└── functions.R
data/
└── my_data.csv
```

### _targets.R
\vspace*{-0.26cm}

```{r}
#| eval: false
library(targets)
tar_source() # source all files in R folder
tar_option_set(packages = c("tidyverse", "fable"))
list(
  tar_target(my_file, "data/my_data.csv", format = "file"),
  tar_target(my_data, read_csv(my_file)),
  tar_target(my_model, model_function(my_data))
)
```

## Generate `_targets.R` in working directory

```{r}
#| eval: false
library(targets)
tar_script()
```

## Useful targets commands

* `tar_make()` to run the pipeline.
* `tar_make(starts_with("fig"))` to run only targets starting with "fig".
* `tar_read(object)` to read a target.
* `tar_load(object)` to load a target.
* `tar_load_everything()` to load all targets.
* `tar_manifest()` to list all targets
* `tar_visnetwork()` to visualize the pipeline.
* `tar_destroy()` to remove all targets.
* `tar_outdated()` to list outdated targets.

## Debugging

Errored targets to return `NULL` so pipeline continues.

```{r}
#| eval: false
tar_option_set(error = "null")
```

\pause

See error messages for all targets.

```{r}
#| eval: false
tar_meta(fields = error, complete_only = TRUE)
```

\pause

See warning messages for all targets.

```{r}
#| eval: false
tar_meta(fields = warnings, complete_only = TRUE)
```

## Debugging
\fontsize{14}{15.5}\sf

* Try loading all available targets: `tar_load_everything()`. Then run the command of the errored target in the console.

* Pause the pipeline with `browser()`

* Use the debug option: `tar_option_set(debug = "target_name")`

* Save the workspaces:

  - `tar_option_set(workspace_on_error = TRUE)`
  - `tar_workspaces()`
  - `tar_workspace(target_name)`

## Random numbers

* Each target runs with its own seed based on its name and the global seed from `tar_option_set(seed = ???)`
* So running only some targets, or running them in a different order, will not change the results.

## Folder structure

```{verbatim}
├── .git/
├── .Rprofile
├── .Renviron
├── renv/
├── index.Rmd
├── _targets/
├── _targets.R
├── _targets.yaml
├── R/
├──── functions_data.R
├──── functions_analysis.R
├──── functions_visualization.R
├── data/
└──── input_data.csv
```

## targets with quarto

```{r}
#| eval: false
library(targets)
library(tarchetypes)                                                 # <1>
tar_source() # source all files in R folder
tar_option_set(packages = c("tidyverse", "fable"))
list(
  tar_target(my_file, "data/my_data.csv", format = "file"),
  tar_target(my_data, read_csv(my_file)),
  tar_target(my_model, model_function(my_data))
  tar_quarto(report, "file.qmd", extra_files = "references.bib")     # <2>
  )
```

1. Load `tarchetypes` package for quarto support.
2. Add a quarto target.

## Exercise

* Add a targets workflow to your quarto document.
* Create a visualization of the pipeline network using `tar_visnetwork()`.

# Reproducible environments

## Reproducible environments

* To ensure that your code runs the same way on different machines and at different times, you need the computing environment to be the same.
  1. Operating system
  2. System components
  3. R version
  4. R packages

* Solutions for 1--4: Docker, Singularity, `containerit`, `rang`
* Solutions for 4: `packrat`, `checkpoint`, `renv`

## renv package

![](../diagrams/renv.png)

## renv package

* `renv::init()` : initialize a new project with a new environment. Adds:
  *  `renv/library` contains all packages used in project
  *  `renv.lock` contains metadata about packages used in project
  *  `.Rprofile` run every time R starts.

* `renv::snapshot()` : save the state of the project to `renv.lock`.

* `renv::restore()` : restore the project to the state saved in `renv.lock`.

## renv package
\fontsize{14}{16}\sf

* renv uses a package cache so you are not repeatedly installing the same packages in multiple projects.
* `renv::install()` can install from CRAN, Bioconductor, GitHub, Gitlab, Bitbucket, etc.
* `renv::update()` gets latest versions of all dependencies from wherever they were installed from.
* Only R packages are supported, not system dependencies, and not R itself.
* renv is not a replacement for Docker or Singularity.
* `renv::deactivate(clean = TRUE)` will remove the renv environment.
