{
  "hash": "af55d5aced44c25b70295392ee63fe98",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: ETC4500/ETC5450 Advanced&nbsp;R&nbsp;programming\nauthor: \"Week 7: Reactive programming with targets and renv\"\nformat:\n  presentation-beamer:\n    fontsize: \"14pt,t\"\n    section-titles: false\n    knitr:\n      opts_chunk:\n        dev: \"cairo_pdf\"\n    fig-width: 7.5\n    fig-height: 3.5\n    include-in-header: ../header.tex\n    colorlinks: true\n    urlcolor: MonashBlue\n    linkcolor: burntorange\n---\n\n\n\n# Reactive programming\n\n## Regular (imperative) programming\n\nConsider how code is usually evaluated...\n\n\n::: {.cell}\n\n```{.r .cell-code}\na <- 1\nb <- 2\nx <- a + b\nx\n```\n:::\n\n\nWhat is `x`?\n\n\n::: {.cell}\n\n```{.r .cell-code}\na <- -1\nx\n```\n:::\n\n\nWhat is `x` now?\n\n## Regular (imperative) programming\n\n::: {.callout-tip title=\"Predictable programming\"}\nAll programming we've seen so far evaluates code in sequential order, line by line.\n\n\\hspace{1em}\n\nSince `x` was not re-evaluated, its value stays the same even when its inputs have changed.\n:::\n\n<!-- . . . -->\n\n<!-- *Note: this is why it's especially important to ensure code works when ran from top to bottom, since when doing a data analysis we often write and run code more freely!* -->\n\n## Reactive programming\n\nWithin a reactive programming paradigm, objects *react* to changes in their inputs and automatically update their value!\n\n. . .\n\n::: {.callout-warning title=\"Disclaimer\"}\nReactive programming is a broad and diverse paradigm, we'll focus only on the basic concepts and how they apply in shiny applications.\n:::\n\n## Reactive programming\n\nWe can implement *reactivity* with functions & environments.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rlang)\nreact <- function(e) new_function(alist(), expr(eval(!!enexpr(e))))\n```\n:::\n\n\nWe'll learn how this function works later (metaprogramming).\n\nReactive programming is also smarter about *'invalidation'*, results are **cached and reused** if the inputs aren't changed.\n\n## Reactive programming\n\nHow does reactive programming differ?\n\n\n::: {.cell}\n\n```{.r .cell-code}\na <- 1\nb <- 2\ny <- react(a + b)\ny()\n```\n:::\n\n\nWhat is `y`?\n\n\n::: {.cell}\n\n```{.r .cell-code}\na <- -1\ny()\n```\n:::\n\n\nWhat is `y` now?\n\n## Reactive programming\n\n::: {.callout-tip title=\"(Un)predictable programming?\"}\nReactive programming can be disorienting!\n\n\\hspace{1em}\n\nReactive objects *invalidate* whenever their inputs change, and so its value will be recalculated and stay up-to-date.\n:::\n\n## Reactive programming\n\n::: {.callout-caution title=\"Your turn!\"}\n<!-- Experiment with using `react()` in R. -->\n\n<!-- ```{r} -->\n<!-- library(rlang) -->\n<!-- react <- function(e) new_function(alist(), expr(eval(!!enexpr(e)))) -->\n<!-- ``` -->\n\n\n::: {.cell}\n\n```{.r .cell-code}\na <- 1\nb <- 2\ny <- react(a + b)\ny()\n```\n:::\n\n\nWhen was `a + b` evaluated?\n\n\\vspace{1em}\n\nHow does this differ from ordinary (imperative) code?\n:::\n\n## Imperative and declarative programming\n\n\\fontsize{13}{13}\\sf\n::: {.callout-note icon=false title=\"Imperative programming\"}\n* Specific commands are carried out immediately.\n* Usually direct and exact instructions.\n* e.g. read in data from this file.\n:::\n\n::: {.callout-note icon=false title=\"Declarative programming\"}\n* Specific commands are carried out when needed.\n* Expresses higher order goals / constraints.\n* e.g. make sure this dataset is up to date every time I see it.\n:::\n\n## Use cases for reactive programming\n\n\\fontsize{13}{13}\\sf\n::: {.callout-important title=\"Use-less cases\"}\nThis paradigm is rarely needed or used in R for data analysis.\n:::\n\n::: {.callout-tip title=\"Useful cases\"}\nReactive programming is useful for developing user applications (including web apps!).\n\n\\vspace{1em}\n\nIn R, the shiny package uses reactive programming for writing app interactivity.\n:::\n\n# Caching\n\n## Caching: using rds\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (file.exists(\"results.rds\")) {\n  res <- readRDS(\"results.rds\")\n} else {\n  res <- compute_it()  # a time-consuming function\n  saveRDS(res, \"results.rds\")\n}\n```\n:::\n\n\n\\pause\\vspace*{1cm}\n\n\\alert{Equivalently\\dots}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres <- xfun::cache_rds(\n  compute_it(), # a time-consuming function\n  file = \"results.rds\"\n)\n```\n:::\n\n\n## Caching: using rds\n\\fontsize{10}{10}\\sf\n\n\n::: {.cell freeze='false'}\n\n```{.r .cell-code}\ncompute <- function(...) {\n    xfun::cache_rds(rnorm(6), file = \"results.rds\", ...)\n}\ncompute()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1.518  0.109 -0.290 -1.273 -0.935  0.397\n```\n\n\n:::\n\n```{.r .cell-code}\ncompute()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1.518  0.109 -0.290 -1.273 -0.935  0.397\n```\n\n\n:::\n:::\n\n\n\n\n\n::: {.cell freeze='false'}\n\n```{.r .cell-code}\ncompute(rerun = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1.072  0.758  0.216  0.194 -2.311  0.277\n```\n\n\n:::\n\n```{.r .cell-code}\ncompute()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1.072  0.758  0.216  0.194 -2.311  0.277\n```\n\n\n:::\n:::\n\n\n## Caching: Rmarkdown\n\n\n````{.default}\n```{r import-data, cache=TRUE}\nd <- read.csv('my-precious.csv')\n```\n\n```{r analysis, dependson='import-data', cache=TRUE}\nsummary(d)\n```\n````\n\n* Requires explicit dependencies or changes not detected.\n* Changes to functions or packages not detected.\n* Good practice to frequently clear cache to avoid problems.\n* targets is a better solution: Week 8\n\n## Caching: Quarto\n\n\n````{.default}\n```{r}\n#| label: import-data\n#| cache: true\nd <- read.csv('my-precious.csv')\n```\n\n```{r}\n#| label: analysis\n#| dependson: import-data\n#| cache: true\nsummary(d)\n```\n````\n\n* Same problems as Rmarkdown\n* targets is a better solution: Week 8\n\n## Caching: memoise\n\nCaching stores results of computations so they can be reused.\n\n\\fontsize{10}{10}\\sf\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(memoise)\nsq <- function(x) {\n  print(\"Computing square of 'x'\")\n  x**2\n}\nmemo_sq <- memoise(sq)\nmemo_sq(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Computing square of 'x'\"\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n\n```{.r .cell-code}\nmemo_sq(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n:::\n\n\n# targets\n\n## targets: reproducible computation at scale\n\n\\placefig{0.5}{1.8}{width=5cm}{images/logo.png}\n\n\\begin{textblock}{15}(0.5,8.5)\n\\textcolor{gray}{\\footnotesize Some images from https://wlandau.github.io/targets-tutorial}\n\\end{textblock}\n\n\\begin{textblock}{10}(6, 2)\n\\begin{itemize}\n\\item Supports a clean, modular, function-oriented programming style.\n\\item Learns how your pipeline fits together.\n\\item Runs only the necessary computation.\n\\item Abstracts files as R objects.\n\\item Similar to Makefiles, but with R functions.\n\\end{itemize}\n\\end{textblock}\n\n## Interconnected tasks\n\n\\only<1>{\\placefig{0.5}{2}{width=13cm}{images/workflow.png}}\n\\only<2>{\\placefig{0.5}{2}{width=13cm}{images/change.png}}\n\\only<3>{\\placefig{0.5}{2}{width=13cm}{images/downstream.png}}\n\n## Dilemma: short runtimes or reproducible results?\n\n\\fullheight{images/decisions.png}\n\n## Let a pipeline tool do the work\n\n\\fullwidth{images/pipeline_graph.png}\\vspace*{-0.15cm}\n\n* Save time while ensuring computational reproducibility.\n* Automatically skip tasks that are already up to date.\n\n## Typical project structure\n\n\n```{.default}\n_targets.R # Required top-level configuration file.\nR/\n└── functions.R\ndata/\n└── my_data.csv\n```\n\n### _targets.R\n\\vspace*{-0.26cm}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(targets)\ntar_source() # source all files in R folder\ntar_option_set(packages = c(\"tidyverse\", \"fable\"))\nlist(\n  tar_target(my_file, \"data/my_data.csv\", format = \"file\"),\n  tar_target(my_data, read_csv(my_file)),\n  tar_target(my_model, model_function(my_data))\n)\n```\n:::\n\n\n## Generate `_targets.R` in working directory\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(targets)\ntar_script()\n```\n:::\n\n\n## Useful targets commands\n\n* `tar_make()` to run the pipeline.\n* `tar_make(starts_with(\"fig\"))` to run only targets starting with \"fig\".\n* `tar_read(object)` to read a target.\n* `tar_load(object)` to load a target.\n* `tar_load_everything()` to load all targets.\n* `tar_manifest()` to list all targets\n* `tar_visnetwork()` to visualize the pipeline.\n* `tar_destroy()` to remove all targets.\n* `tar_outdated()` to list outdated targets.\n\n## Debugging\n\nErrored targets to return `NULL` so pipeline continues.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntar_option_set(error = \"null\")\n```\n:::\n\n\n\\pause\n\nSee error messages for all targets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntar_meta(fields = error, complete_only = TRUE)\n```\n:::\n\n\n\\pause\n\nSee warning messages for all targets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntar_meta(fields = warnings, complete_only = TRUE)\n```\n:::\n\n\n## Debugging\n\\fontsize{14}{15.5}\\sf\n\n* Try loading all available targets: `tar_load_everything()`. Then run the command of the errored target in the console.\n\n* Pause the pipeline with `browser()`\n\n* Use the debug option: `tar_option_set(debug = \"target_name\")`\n\n* Save the workspaces:\n\n  - `tar_option_set(workspace_on_error = TRUE)`\n  - `tar_workspaces()`\n  - `tar_workspace(target_name)`\n\n## Random numbers\n\n* Each target runs with its own seed based on its name and the global seed from `tar_option_set(seed = ???)`\n* So running only some targets, or running them in a different order, will not change the results.\n\n## Folder structure\n\n\n```{.default}\n├── .git/\n├── .Rprofile\n├── .Renviron\n├── renv/\n├── index.Rmd\n├── _targets/\n├── _targets.R\n├── _targets.yaml\n├── R/\n├──── functions_data.R\n├──── functions_analysis.R\n├──── functions_visualization.R\n├── data/\n└──── input_data.csv\n```\n\n## targets with quarto\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(targets)\nlibrary(tarchetypes)                                                 # <1>\ntar_source() # source all files in R folder\ntar_option_set(packages = c(\"tidyverse\", \"fable\"))\nlist(\n  tar_target(my_file, \"data/my_data.csv\", format = \"file\"),\n  tar_target(my_data, read_csv(my_file)),\n  tar_target(my_model, model_function(my_data))\n  tar_quarto(report, \"file.qmd\", extra_files = \"references.bib\")     # <2>\n  )\n```\n:::\n\n\n1. Load `tarchetypes` package for quarto support.\n2. Add a quarto target.\n\n## Exercise\n\n* Add a targets workflow to your quarto document.\n* Create a visualization of the pipeline network using `tar_visnetwork()`.\n\n# Reproducible environments\n\n## Reproducible environments\n\n* To ensure that your code runs the same way on different machines and at different times, you need the computing environment to be the same.\n  1. Operating system\n  2. System components\n  3. R version\n  4. R packages\n\n* Solutions for 1--4: Docker, Singularity, `containerit`, `rang`\n* Solutions for 4: `packrat`, `checkpoint`, `renv`\n\n## renv package\n\n![](../diagrams/renv.png)\n\n## renv package\n\n* `renv::init()` : initialize a new project with a new environment. Adds:\n  *  `renv/library` contains all packages used in project\n  *  `renv.lock` contains metadata about packages used in project\n  *  `.Rprofile` run every time R starts.\n\n* `renv::snapshot()` : save the state of the project to `renv.lock`.\n\n* `renv::restore()` : restore the project to the state saved in `renv.lock`.\n\n## renv package\n\\fontsize{14}{16}\\sf\n\n* renv uses a package cache so you are not repeatedly installing the same packages in multiple projects.\n* `renv::install()` can install from CRAN, Bioconductor, GitHub, Gitlab, Bitbucket, etc.\n* `renv::update()` gets latest versions of all dependencies from wherever they were installed from.\n* Only R packages are supported, not system dependencies, and not R itself.\n* renv is not a replacement for Docker or Singularity.\n* `renv::deactivate(clean = TRUE)` will remove the renv environment.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}